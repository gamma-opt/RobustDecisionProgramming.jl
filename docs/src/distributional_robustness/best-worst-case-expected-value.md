# [Best Worst-Case Expected Value](@id best-worst-case-expected-value)
## Probability Distribution
We denote a finite set of **states** for probabilities and utilities as

$$I=\{1,2,...,k\},\quad kâˆˆâ„•.$$

We define a vector of discrete **probabilities** associated with the states as

$$ğ©=(p_1,p_2,...,p_k),$$

such that all elements are greater or equal to zero $ğ©â‰¥0$ and the sum of all elements is one $ğ©â‹…ğŸ(k)=1$ where $ğŸ(k)=(1)^k$ is a vector of $k$ ones and $â‹…$ is the dot product. We also define **utilities** associated with the states as a vector of real numbers

$$ğ®=(u_1,u_2,...,u_k)âˆˆâ„^k.$$

Together, a vector of probabilities and utilities define a **probability distribution**.


## [Maximin Expected Value](@id maximin-expected-value)
We can define the **expected value** as the dot product of probabilities and utilities

$$ğ”¼(ğ©,ğ®)=ğ©â‹…ğ®.$$

We define an **uncertainty set** as a set of probability vectors $ğ.$ In decision programming, a chance node has multiple states and each state is associated with a probability distribution. Hence, in robust decision programming, each probability vector is associated with an uncertainty set. We need to account for all combinations of the uncertainty sets by formulating the maximin expected value to over a product of the uncertainty sets.

We denote multiple uncertainty sets as $ğ_1,...,ğ_m$ with indices $L=\{1,...,m\}$ where $mâˆˆâ„•.$ Then, a **product uncertainty set** is

$$ğ_L^{Ã—}=âˆ_{lâˆˆL} ğ_{l}.$$

Given multiple utility vectors $ğ®_1,...,ğ®_m$, we define the problem as maximizing the minimum expected value over the product uncertainty set over decision variables $Z$ similar to [Wald's maximin model](https://en.wikipedia.org/wiki/Wald%27s_maximin_model)

$$\max_{zâˆˆZ}\, \min_{(ğª_1,...,ğª_m)âˆˆğ_L^{Ã—}} âˆ‘_{lâˆˆL} ğ”¼(ğª_l, ğ®_l(z)).$$

We can simplify the formulation to a more computationally tractable form

$$\max_{zâˆˆZ}\, âˆ‘_{lâˆˆL} \min_{ğªâˆˆğ_l} ğ”¼(ğª, ğ®_l(z)).$$

Now, we can reformulate the maximin over product uncertainty set in mathematical programming as

$$\max_{zâˆˆZ}\, âˆ‘_{lâˆˆL} x_l$$

$$x_l â‰¤ ğ”¼(ğª, ğ®_l(z)),\quad âˆ€ğªâˆˆğ_{l},\, lâˆˆL$$


## Local Uncertainty Set
We can formulate a **local uncertainty set** $ğ_{ğ©}$ around a **pivot probability** $ğ©$ by formulating a **local ambiguity set** $ğƒ_{ğ©}$ of **deviations** $ğ$ such that each element of the uncertainty set satisfies

$$ğª=ğ©+ğ.$$

We can express the uncertainty set in terms of the ambiguity set as

$$ğ_ğ©=\{ğ©+ğâˆ£ğâˆˆğƒ_ğ©\}.$$

We can also define the minimum expected value over the local uncertainty set in terms of the local ambiguity set

$$\min_{ğªâˆˆğ_ğ©} ğ”¼(ğª, ğ®) = \min_{ğâˆˆğƒ_ğ©} ğ”¼(ğ©+ğ, ğ®) = ğ”¼(ğ©,ğ®) + \min_{ğâˆˆğƒ_ğ©} ğ”¼(ğ,ğ®).$$

Therefore, we can focus on forming the local ambiguity set and minimizing expected value over it.


## Local Ambiguity Set
We define the **lower bounds** $ğ^{-}â‰¤0$ and **upper bounds** $ğ^{+}â‰¥0$ for deviations $ğ$ as parameters such that

$$ğ^{-}â‰¤ğâ‰¤ğ^{+}.$$

As a consequence from the properties of discrete probabilities, we obtain

$$ğª^{+}=ğ©+ğ^{+}â‰¤1 â‡’\quad ğ^{+}â‰¤1-ğ©,$$

$$ğª^{-}=ğ©+ğ^{-}â‰¥0 â‡’\quad ğ^{-}â‰¥-ğ©.$$

We also obtain the **conservation of probability mass** as

$$ğâ‹…ğŸ(k)=(ğ©-ğª)â‹…ğŸ(k)=ğ©â‹…ğŸ(k)-ğªâ‹…ğŸ(k)=0.$$

Finally, we can limit the Wasserstein distance of uncertainty set elements from the pivot by constraining the magnitude of the deviation to $lâˆˆâ„•$ norm less or equal to an **uncertainty radius** $0â‰¤Ïµâ‰¤1$ as

$$\|ğ\|_lâ‰¤2Ïµ.$$

By setting $Ïµ=1$ we can make the magnitude constraint inactive.

---

Given parameters lower bound $-ğ©â‰¤ğ^{-}â‰¤0$, upper bound $0â‰¤ğ^{+}â‰¤1-ğ©$, and uncertainty radius $0â‰¤Ïµâ‰¤1,$ the **continuous local ambiguity set** is the set of all deviations that satisfy the defined constraints

$$\bar{ğƒ}_ğ©=\{ğâˆˆ[ğ^{-},ğ^{+}]âˆ£ ğâ‹…ğŸ(k)=0,\, \|ğ\|_lâ‰¤2Ïµ\}.$$

The ambiguity set is convex, which makes optimization tractable. Smaller values of $l$ make the ambiguity set more pessimistic and larger values more optimistic. We refer to the ambiguity set as **polyhedral** when $l=1.$

To form an explicit formulation of the mathematical programming model, we have to **discretize** the ambiguity set. A **discrete local ambiguity set** $ğƒ_ğ©$ is a finite subset of $\bar{ğƒ}_ğ©$ such that it contains all deviations $ğ$ for all utility vectors $ğ®âˆˆâ„^{k}$ that can minimize the expected value. We can solve the discretization for [local polyhedral ambiguity set](@ref polyhedral-ambiguity-set) using the **cross-assignment** algorithm.


## Proof of Convexity of Ambiguity Set
Let $ğ_1,ğ_2âˆˆğƒ_ğ©,$ we must show that $ğâˆˆğƒ_ğ©$ where $ğ=(1-Î»)ğ_1+Î»ğ_2$ with $Î»âˆˆ[0,1].$

1) Minimum: $ğ=(1-Î»)ğ_1+Î»ğ_2â‰¥(1-Î»)ğ^{-}+Î»ğ^{-}=ğ^{-}.$
2) Maximum: $ğ=(1-Î»)ğ_1+Î»ğ_2â‰¤(1-Î»)ğ^{+}+Î»ğ^{+}=ğ^{+}.$
3) Conservation of probability mass: $ğâ‹…ğŸ(k)=(1-Î»)ğ_1â‹…ğŸ(k)+Î»ğ_2â‹…ğŸ(k)=0$
4) Limit for magnitude (Triangle inequality): $\|ğ\|_lâ‰¤(1-Î»)\|ğ_1\|_l+Î»\|ğ_2\|_lâ‰¤2Ïµ$
