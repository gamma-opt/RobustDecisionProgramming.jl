# Uncertainty Sets
## Continuous Uncertainty Set
Given two finite sets of discrete probabilities $ğ©$ and $ğª$ over states $I,$ we define the difference between the distributions as

$$ğ=ğ©-ğª.$$

From the properties of discrete probabilities, we have

$$ğâ‹…ğŸ(k)=(ğ©-ğª)â‹…ğŸ(k)=ğ©â‹…ğŸ(k)-ğªâ‹…ğŸ(k)=0.$$

We obtain the bounds for the values of the differences by taking the minimum and maximum over the set of all possible differences. Since the value of probabilities are between zero and one, we have

$$-1â‰¤ğâ‰¤1.$$

We can reformulate the difference equation such when difference $ğ$ added to the original distribution $ğ©$ yield the new distribution $ğª$ as

$$ğª=ğ©+ğ$$

The **difference set** consists of all possible difference vectors that yield a valid distribution when added to the original distribution

$$ğƒ=\{ğâˆ£-1â‰¤ğâ‰¤1,\, ğâ‹…ğŸ(k)=0,\, ğ©+ğâ‰¥0\}.$$

We can define a boolean function to limit the magnitude of the difference vectors as

$$\mathcal{C}:ğƒâ†’\{âŠ¥,âŠ¤\}.$$

We filter the difference set using the boolean function as a constraint into an **ambiguity set**

$$\bar{Î”} = \{ğâˆˆğƒâˆ£\mathcal{C}(ğ)\}$$

The function $\mathcal{C}$ is a design choice. We discuss concrete choices of the function later.

Properties of $\mathcal{C}$, convexity of $\bar{Î”}$, polyhedral sets.

The **continuous uncertainty set** consists of all distributions  within difference $ğâˆˆ\bar{Î”}$ from $ğ©$ as

$$\bar{ğ}=\{ğ©+ğâˆ£ğâˆˆ\bar{Î”}\}.$$


## Discretization
The minimum expected value is

$$\min_{ğªâˆˆ\bar{ğ}} ğªâ‹…ğ® = \min_{ğâˆˆ\bar{Î”}} (ğ©+ğ)â‹…ğ® = ğ©â‹…ğ® + \min_{ğâˆˆ\bar{Î”}} ğâ‹…ğ®.$$

To formulate the minimization problem as a discrete optimization formulation, we need to reduce $\bar{Î”}$ to a discrete set of possible difference vectors $Î”$ such that with known $ğ®$ we have $ğ^{âˆ—}âˆˆÎ”$ where

$$ğ^{âˆ—}=\argmin_{ğâˆˆ\bar{Î”}} ğâ‹…ğ®.$$

We define the following lemma for solving the problem:

---

Lemma: If $u_1>u_2$ and $d_1<d_2â‰¤0,$ then:

$$\begin{aligned}
u_1 d_1 + u_2 d_2 &= u_1 d_1^{â€²}+ u_1 d_1^{â€²â€²}+u_2 d_2 \\
&< u_1 d_1^{â€²} + u_2 d_1^{â€²â€²} + u_2 d_2 \\
&= u_1 d_1^{â€²} + u_2 (d_1^{â€²â€²} + d_2)
\end{aligned}$$

where $d_1=d_1^{â€²}+d_1^{â€²â€²}$ such that $d_1^{â€²}>d_1$ and $d_1^{â€²â€²}>d_1.$

Assign smallest $d$ to highest $u$ and vice versa.

---

Generate solution for each permutation

$$u_{1}â‰¥u_{2}â‰¥...â‰¥u_{k}$$

If we do not have any information about the ordering of $ğ®,$ we can generate all permutations to cover all possible orderings

Let $\mathcal{P}(I)$ define the set of all permutations of set $I.$

$ğ^{âˆ—}(I^{â€²})$ assuming order $u_{i_1}â‰¥u_{i_2}â‰¥...â‰¥u_{i_k}$ where $I^{â€²}=\{i_1,i_2,...,i_k\}$

$$Î”=\{ğ^{âˆ—}(I^{â€²})âˆ£I^{â€²}âˆˆ\mathcal{P}(I)\}$$

The discrete set of all possible minimizing distributions

$$ğ=\{ğ©+ğâˆ£ğâˆˆÎ”\}$$


## Wasserstein Distance
Mean that $\mathcal{C}(ğ)$ is equivalent to

$$\|ğ\|_1â‰¤2Ïµ$$

where $0â‰¤Ïµâ‰¤1$ is a parameter

---

$$\begin{aligned}
\min &\, d_1 u_1 +d_2 u_2 +...+d_k u_k \\
& d_1+d_2+...+d_k=0 \\
& |d_1|+|d_2|+...+|d_k|â‰¤2Ïµ \\
& p_i + d_i â‰¥ 0,\quad âˆ€iâˆˆ\{1,2,...,k\} \\
& d_iâˆˆâ„,\quad âˆ€iâˆˆ\{1,2,...,k\}
\end{aligned}$$

---

Solution. Let $u_1â‰¥u_2â‰¥...â‰¥u_k$ and $k>1.$

$$Ïµ^{â€²}=\min\{Ïµ,1-p_k\}$$

Decrease the probability of best outcomes:

$$\begin{aligned}
m_1 &= Ïµ^{â€²} \\
d_1 &= -\min\{m_1,p_1\} \\
m_2 &= m_1 + d_1 \\
d_2 &= -\min\{m_2,p_2\},\quad m_2 > 0 \\
&â‹®
\end{aligned}$$

Increase the probability of worst outcomes.

$$d_k=Ïµ^{â€²}$$

Difference vector

$$ğ^{âˆ—}=(d_1,d_2,...,d_k)$$

Set of all difference vectors


## Probability Intervals
Means that $\mathcal{C}(ğ)$ is equivalent to

$$0â‰¤ğ^{-} â‰¤ ğ â‰¤ ğ^{+}â‰¤1$$

where $ğ^{-}$ and $ğ^{+}$ are parameters
