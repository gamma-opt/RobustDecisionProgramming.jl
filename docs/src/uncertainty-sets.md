# Uncertainty Sets
## Continuous Uncertainty Set
Given two finite sets of discrete probabilities $ğ©$ and $ğª$ over states $I,$ we define the **difference** between the distributions as

$$ğ=ğª-ğ©.$$

As a consequence from the properties of discrete probabilities, the **sum of the differences is zero**

$$ğâ‹…ğŸ(k)=(ğ©-ğª)â‹…ğŸ(k)=ğ©â‹…ğŸ(k)-ğªâ‹…ğŸ(k)=0.$$

We can also obtain the bounds for the values of the differences by taking the minimum and maximum over the set of all possible differences. Since the value of probabilities are between zero and one, we have

$$-1â‰¤ğâ‰¤1.$$

We can reformulate the difference equation into a form

$$ğª=ğ©+ğ$$

The **difference set** consists of all possible difference vectors $ğ$ that yield a valid distribution when added to the distribution $ğ©.$ Formally,

$$ğƒ_ğ©=\{ğâˆ£-1â‰¤ğâ‰¤1,\, ğâ‹…ğŸ(k)=0,\, ğ©+ğâ‰¥0\}.$$

Next, we define an **ambiguity set** as a subset of differences set

$$\bar{Î”}_ğ© = \{ğâˆˆğƒ_ğ©âˆ£\mathcal{C}(ğ)\}$$

The constraint (boolean function) $\mathcal{C}$ limits the elements' magnitude. We need to choose the constraint $\mathcal{C}$ such that the resulting set is convex, which makes optimization possible. We discuss concrete choices that yield polyhedral sets later.

Finally, we define the **continuous uncertainty set** that consists of all distributions within difference $ğâˆˆ\bar{Î”}$ from $ğ©$

$$\bar{ğ}=\{ğ©+ğâˆ£ğâˆˆ\bar{Î”}\}.$$

However, we cannot use a continuous uncertainty set directly for formulating the mathematical model. We must discretize it first.


## Discretization
The minimum expected value is

$$\min_{ğªâˆˆ\bar{ğ}} ğªâ‹…ğ® = \min_{ğâˆˆ\bar{Î”}} (ğ©+ğ)â‹…ğ® = ğ©â‹…ğ® + \min_{ğâˆˆ\bar{Î”}} ğâ‹…ğ®.$$

To formulate the minimization problem as a discrete optimization formulation, we need to reduce $\bar{Î”}$ to a discrete set of possible difference vectors $Î”$ such that with known $ğ®$ we have $ğ^{âˆ—}âˆˆÎ”$ where

$$ğ^{âˆ—}=\argmin_{ğâˆˆ\bar{Î”}} ğâ‹…ğ®.$$

We define the following lemma for solving the problem:

---

Lemma: If $u_1>u_2$ and $d_1<d_2â‰¤0,$ then:

$$\begin{aligned}
u_1 d_1 + u_2 d_2 &= u_1 d_1^{â€²}+ u_1 d_1^{â€²â€²}+u_2 d_2 \\
&< u_1 d_1^{â€²} + u_2 d_1^{â€²â€²} + u_2 d_2 \\
&= u_1 d_1^{â€²} + u_2 (d_1^{â€²â€²} + d_2)
\end{aligned}$$

where $d_1=d_1^{â€²}+d_1^{â€²â€²}$ such that $d_1^{â€²}>d_1$ and $d_1^{â€²â€²}>d_1.$

Assign smallest $d$ to highest $u$ and vice versa.

---

Generate solution for each permutation

$$u_{1}â‰¥u_{2}â‰¥...â‰¥u_{k}$$

If we do not have any information about the ordering of $ğ®,$ we can generate all permutations to cover all possible orderings

Let $\mathcal{P}(I)$ define the set of all permutations of set $I.$

$ğ^{âˆ—}(I^{â€²})$ assuming order $u_{i_1}â‰¥u_{i_2}â‰¥...â‰¥u_{i_k}$ where $I^{â€²}=\{i_1,i_2,...,i_k\}$

$$Î”=\{ğ^{âˆ—}(I^{â€²})âˆ£I^{â€²}âˆˆ\mathcal{P}(I)\}$$

The discrete set of all possible minimizing distributions

$$ğ=\{ğ©+ğâˆ£ğâˆˆÎ”\}$$


## Wasserstein Distance
Mean that $\mathcal{C}(ğ)$ is equivalent to

$$\|ğ\|_1â‰¤2Ïµ$$

where $0â‰¤Ïµâ‰¤1$ is a parameter

---

$$\begin{aligned}
\min &\, d_1 u_1 +d_2 u_2 +...+d_k u_k \\
& d_1+d_2+...+d_k=0 \\
& |d_1|+|d_2|+...+|d_k|â‰¤2Ïµ \\
& p_i + d_i â‰¥ 0,\quad âˆ€iâˆˆ\{1,2,...,k\} \\
& d_iâˆˆâ„,\quad âˆ€iâˆˆ\{1,2,...,k\}
\end{aligned}$$

---

Solution. Let $u_1â‰¥u_2â‰¥...â‰¥u_k$ and $k>1.$

$$Ïµ^{â€²}=\min\{Ïµ,1-p_k\}$$

Decrease the probability of best outcomes:

$$\begin{aligned}
m_1 &= Ïµ^{â€²} \\
d_1 &= -\min\{m_1,p_1\} \\
m_2 &= m_1 + d_1 \\
d_2 &= -\min\{m_2,p_2\},\quad m_2 > 0 \\
&â‹®
\end{aligned}$$

Increase the probability of worst outcomes.

$$d_k=Ïµ^{â€²}$$

Difference vector

$$ğ^{âˆ—}=(d_1,d_2,...,d_k)$$

Set of all difference vectors


## Probability Intervals
Means that $\mathcal{C}(ğ)$ is equivalent to

$$0â‰¤ğ^{-} â‰¤ ğ â‰¤ ğ^{+}â‰¤1$$

where $ğ^{-}$ and $ğ^{+}$ are parameters
