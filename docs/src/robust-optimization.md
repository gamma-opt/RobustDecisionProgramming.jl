# Robust Optimization
## Introduction
Focus on distributionally robust over discrete probability distributions. Best worst-case analysis.

We denote scalar using lower-case math italics, vectors using lower-case boldface symbols, and sets using upper-case symbols. All non-matrix algebra operations on vectors are element-wise.

We denote vector constructors using $(elementâˆ£condition)$ and set constructors using $\{elementâˆ£condition\}.$

## Discrete Probabilities
We denote a finite set of discrete probabilities for states $I=\{1,2,...,k\}$ as

$$ğ©=(p_1,p_2,...,p_k),$$

such that $ğ©â‰¥0$ and $ğ©â‹…ğŸ(k)=1$ where $ğŸ(k)=(1)^k$ is a vector of $k$ ones.


## Difference
Given two finite sets of discrete probabilities $ğ©$ and $ğª$ over states $I,$ we define the difference between the distributions as

$$ğ=ğ©-ğª.$$

From the properties of discrete probabilities, we have

$$ğâ‹…ğŸ(k)=(ğ©-ğª)â‹…ğŸ(k)=ğ©â‹…ğŸ(k)-ğªâ‹…ğŸ(k)=0.$$

We obtain the bounds for the values of the differences by taking the minimum and maximum over the set of all possible differences. Since the value of probabilities are between zero and one, we have

$$-1â‰¤ğâ‰¤1.$$


## Uncertainty Sets
We can reformulate the difference equation such when difference $ğ$ added to the original distribution $ğ©$ yield the new distribution $ğª$ as

$$ğª=ğ©+ğ$$

The **difference set** consists of all possible difference vectors that yield a valid distribution when added to the original distribution

$$ğƒ=\{ğâˆ£-1â‰¤ğâ‰¤1,\, ğâ‹…ğŸ(k)=0,\, ğ©+ğâ‰¥0\}.$$

We can define a boolean function to limit the magnitude of the difference vectors as

$$\mathcal{C}:ğƒâ†’\{âŠ¥,âŠ¤\}.$$

We filter the difference set using the boolean function as a constraint into an **ambiguity set**

$$Î” = \{dâˆˆğƒâˆ£\mathcal{C}(ğ)\}$$

The function $\mathcal{C}$ is a design choice. We discuss concrete choices of the function later.

Properties of $\mathcal{C}$, convexity of $Î”$, polyhedral sets.

The **uncertainty set** consists of all distributions  within difference $ğâˆˆÎ”$ from $ğ©$ as

$$ğ=\{ğ©+ğâˆ£ğâˆˆÎ”\}.$$


## Minimum Expected Value
We define a vector of real numbers associated with states $I$ as

$$ğ®=(u_1,u_2,...,u_k)âˆˆâ„^k$$

Then, we define the minimum expected value as

$$\min_{ğªâˆˆğ} ğªâ‹…ğ® = \min_{ğâˆˆÎ”} (ğ©+ğ)â‹…ğ® = ğ©â‹…ğ® + \min_{ğâˆˆÎ”} ğâ‹…ğ®.$$

To formulate the minimization problem as a discrete optimization formulation, we need to reduce $Î”$ to a discrete set of possible difference vectors $Î”^{-}$ such that $ğ^{-}âˆˆÎ”^{-}$ where

$$ğ^{-}=\argmin_{ğâˆˆÎ”} ğâ‹…ğ®.$$

We define the following lemma for solving the problem:

---

Lemma: If $u_1>u_2$ and $d_1<d_2â‰¤0,$ then:

$$\begin{aligned}
u_1 d_1 + u_2 d_2 &= u_1 d_1^{â€²}+ u_1 d_1^{â€²â€²}+u_2 d_2 \\
&< u_1 d_1^{â€²} + u_2 d_1^{â€²â€²} + u_2 d_2 \\
&= u_1 d_1^{â€²} + u_2 (d_1^{â€²â€²} + d_2)
\end{aligned}$$

where $d_1=d_1^{â€²}+d_1^{â€²â€²}$ such that $d_1^{â€²}>d_1$ and $d_1^{â€²â€²}>d_1.$

Assign smallest $d$ to highest $u$ and vice versa.

---

Generate solution for each permutation

$$u_{1}â‰¥u_{2}â‰¥...â‰¥u_{k}$$

If we do not have any information about the ordering of $ğ®,$ we can generate all permutations to cover all possible orderings

Let $\mathcal{P}(I)$ define the set of all permutations of set $I.$

$ğ^{-}(I^{â€²})$ assuming order $u_{i_1}â‰¥u_{i_2}â‰¥...â‰¥u_{i_k}$ where $I^{â€²}=\{i_1,i_2,...,i_k\}$

$$Î”^{-}=\{ğ^{-}(I^{â€²})âˆ£I^{â€²}âˆˆ\mathcal{P}(I)\}$$


## Maximin over Uncertainty Set
The discrete set of all possible minimizing distributions

$$ğ^{-}=\{ğ©+ğâˆ£ğâˆˆÎ”^{-}\}$$

Maximize the minimum expected value

$$\max_{zâˆˆZ} \min_{ğªâˆˆğ^{-}(z)} ğªâ‹…ğ®(z)$$

Now we can linearize the objective as

$$\max_{zâˆˆZ} x$$

$$xâ‰¤ğªâ‹…ğ®(z),\quad âˆ€ğªâˆˆğ^{-}(z)$$


## Maximin over Product of Uncertainty Sets

$$\max_{zâˆˆZ} x$$

$$x â‰¤ \min_{(ğª_1,...,ğª_m)âˆˆğ^{Ã—}(z)} âˆ‘_{i=1}^m ğª_iâ‹…ğ®_i(z),\quad ğ^{Ã—}(z)=âˆ_{i=1}^m ğ_i^{-}(z)$$

Linearized

$$x â‰¤ âˆ‘_{i=1}^m x_i$$

$$x_i â‰¤ ğª_iâ‹…ğ®_i(z),\quad âˆ€iâˆˆ\{1,...,m\}$$


## Wasserstein Distance
Mean that $\mathcal{C}(ğ)$ is equivalent to

$$\|ğ\|_1â‰¤2Ïµ$$

where $0â‰¤Ïµâ‰¤1$ is a parameter

---

$$\begin{aligned}
\min &\, d_1 u_1 +d_2 u_2 +...+d_k u_k \\
& d_1+d_2+...+d_k=0 \\
& |d_1|+|d_2|+...+|d_k|â‰¤2Ïµ \\
& p_i + d_i â‰¥ 0,\quad âˆ€iâˆˆ\{1,2,...,k\} \\
& d_iâˆˆâ„,\quad âˆ€iâˆˆ\{1,2,...,k\}
\end{aligned}$$

---

Solution. Let $u_1â‰¥u_2â‰¥...â‰¥u_k$ and $k>1.$

$$Ïµ^{â€²}=\min\{Ïµ,1-p_k\}$$

Decrease the probability of best outcomes:

$$\begin{aligned}
m_1 &= Ïµ^{â€²} \\
d_1 &= -\min\{m_1,p_1\} \\
m_2 &= m_1 + d_1 \\
d_2 &= -\min\{m_2,p_2\},\quad m_2 > 0 \\
&â‹®
\end{aligned}$$

Increase the probability of worst outcomes.

$$d_k=Ïµ^{â€²}$$

Difference vector

$$ğ^{-}=(d_1,d_2,...,d_k)$$

Set of all difference vectors


## Intervals
Means that $\mathcal{C}(ğ)$ is equivalent to

$$0â‰¤ğ^{-} â‰¤ ğ â‰¤ ğ^{+}â‰¤1$$

where $ğ^{-}$ and $ğ^{+}$ are parameters
