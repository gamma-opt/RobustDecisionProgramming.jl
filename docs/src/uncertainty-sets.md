# Uncertainty Sets
## Continuous Uncertainty Set
Given two finite sets of discrete probabilities $ğ©$ and $ğª$ over states $I,$ we define the **difference** between the distributions as

$$ğ=ğª-ğ©.$$

---

Since probabilities $ğª=ğ©+ğ$ cannot be less than zero or greater than one, we have the lower and upper bounds for differences as

$$0â‰¤ğ©+ğâ‰¤1$$

$$-ğ©â‰¤ğâ‰¤1-ğ©.$$

Furthermore, we want to give **lower bounds** and **upper bounds** as parameters such that

$$ğ^{-}â‰¤ğâ‰¤ğ^{+},$$

where $-ğ©â‰¤ğ^{-}â‰¤0$ and $0â‰¤ğ^{+}â‰¤1-ğ©,$ which quarantees that $ğ©$ belongs to the difference set.

---

As a consequence of the properties of discrete probabilities, the **sum of the differences is zero**

$$ğâ‹…ğŸ(k)=(ğ©-ğª)â‹…ğŸ(k)=ğ©â‹…ğŸ(k)-ğªâ‹…ğŸ(k)=0.$$

---

Additionally, we can limit the magnitude of the differences with $lâˆˆâ„•$ norm

$$\|ğ\|_lâ‰¤2Ïµ,$$

with a **radius** parameter $0â‰¤Ïµâ‰¤1.$

---

The **ambiguity set** consists of all possible difference vectors $ğ$ that yield a valid distribution when added to the distribution $ğ©.$ Formally,

$$ğƒ_ğ©=\{ğâˆˆ[ğ^{-},ğ^{+}]âˆ£ ğâ‹…ğŸ(k)=0,\, \|ğ\|_lâ‰¤2Ïµ\}.$$

The ambiguity set is convex, which makes optimization possible. Decreasing $l$ makes the model more pessimistic. Using $l=1$ we receive a **polyhedral ambiguity set**.

---

Finally, we define the **continuous uncertainty set** that consists of all distributions within difference $ğâˆˆğƒ_ğ©$ from $ğ©$

$$\bar{ğ}_ğ©=\{ğ©+ğâˆ£ğâˆˆğƒ_ğ©\}.$$

However, we cannot use a continuous uncertainty set directly for formulating the mathematical model. We must obtain a discrete subset of the continuous uncertainty set to linearize the minimum expected value in the [Best Worst-Case Expected Value](@ref) page.


## Discretization
We can define the minimum expected value over the continuous uncertainty set as

$$\min_{ğªâˆˆ\bar{ğ}_ğ©} ğ”¼(ğª, ğ®) = \min_{ğâˆˆğƒ_ğ©} (ğ©+ğ)â‹…ğ® = ğ©â‹…ğ® + \min_{ğâˆˆğƒ_ğ©} ğâ‹…ğ®.$$

We can express the minimizing difference as

$$ğ^{âˆ—}(ğ®)=\argmin_{ğâˆˆğƒ_ğ©} ğâ‹…ğ®.$$

Now, we can obtain a discrete ambiguity set

$$Î”_ğ©=\{ğ^{âˆ—}(ğ®)âˆ£âˆ€ğ®\}.$$

The discrete set of all possible minimizing distributions

$$ğ_ğ©=\{ğ©+ğâˆ£ğâˆˆÎ”_ğ©\}.$$


## Polyhedral Uncertainty Set
We have the minimization problem over polyhedral ambiguity set with the objective

$$\argmin_{(d_1,...,d_k)âˆˆâ„^k} \, d_1â‹…u_1 +d_2â‹…u_2 +...+d_kâ‹…u_k.$$

We have constraints for the difference sum, difference intervals and Wasserstein distance. The difference sum constraint is

$$d_1+d_2+...+d_k=0.$$

The difference interval constraints are

$$d_i^{-} â‰¤ d_i â‰¤ d_i^{+}, \quad âˆ€iâˆˆ\{1,...,k\}.$$

The parameters are **lower bound** $-p_iâ‰¤d_i^{-}â‰¤0$ and **upper bound** $0â‰¤d_i^{+}â‰¤1-p_i$ for all $iâˆˆ\{1,...,k\}.$

The Wasserstein distance constraint is

$$\|ğ\|_1=|d_1|+|d_2|+...+|d_k|â‰¤2Ïµ.$$

The **radius** parameter is $0â‰¤Ïµâ‰¤1.$


## Cross-Assignment
Given an ordering of vector $ğ®$, such as $u_1â‰¤u_2â‰¤...â‰¤u_k$ with corresponding vector of indices $I^{â€²}=(1,2,...,k),$ we can find the minimizing difference vector $ğ^{âˆ—}$ over polyhedral ambiguity set using **cross-assignment**.

The following sections show that we always have difference vector that evaluates to less or equal to zero. After that, we state the rules for finding the minimizing difference vector.

### Binary cross-assignment
Let $u_1â‰¤u_2$ and $d_1+d_2=0$ where $d_1â‰¥0$ and $d_2â‰¤0$. Then we have

$$\begin{aligned}
u_1â‹…d_1 + u_2â‹…d_2 &â‰¤ 0 \\
u_1â‹…d_1 &â‰¤ u_2â‹…(-d_2) \\
u_1â‹…d_1 &â‰¤ u_2â‹…d_1 \\
u_1 &â‰¤ u_2.
\end{aligned}$$

### $k$-ary cross-assignment
Let $u_1â‰¤u_2â‰¤...â‰¤u_k$ and $d_1+d_2+...+d_k=0$.

Then, for all $jâˆˆ\{1,...,k-1\}$ such that $d_1,...,d_jâ‰¥0$ and $d_{j+1},...,d_kâ‰¤0$ we have

$$\begin{aligned}
u_1â‹…d_1 + ... + u_kâ‹…d_k &â‰¤ u_jâ‹…d_1 + ... + u_jâ‹…d_j + u_{j+1}â‹…d_{j+1} + ... + u_{j+1}â‹…d_{k} \\
&= u_jâ‹…(d_1+...+d_j) + u_{j+1}â‹…(d_{j+1}+...+d_k) \\
& â‰¤ 0.
\end{aligned}$$

We obtain the last step from binary cross-assignment.

### Minimizing cross-assignment
Let $u_1â‰¤u_2$ and $d_1+d_2=d_1^{â€²}+d_2^{â€²}.$ Then

$$u_1â‹…d_1+u_2â‹…d_2â‰¤u_1â‹…d_1^{â€²}+u_2â‹…d_2^{â€²}$$

---

Let $d_1,d_2,d_1^{â€²},d_2^{â€²},d^{â€²â€²}â‰¤0.$ Then

$$\begin{aligned}
u_1â‹…d_1+u_2â‹…d_2 &= u_1â‹…d_1+u_2â‹…(d_2^{â€²}+d^{â€²â€²}) \\
&= u_1â‹…d_1+u_2â‹…d^{â€²â€²}+u_2â‹…d_2^{â€²} \\
&â‰¤ u_1â‹…d_1+u_1â‹…d^{â€²â€²}+u_2â‹…d_2^{â€²} \\
&= u_1â‹…(d_1+d^{â€²â€²})+u_2â‹…d_2^{â€²} \\
&= u_1â‹…d_1^{â€²}+u_2â‹…d_2^{â€²},
\end{aligned}$$

where $d_1=d_1^{â€²}-d^{â€²â€²}$ and $d_2=d_2^{â€²}+d^{â€²â€²}.$

---

Let $d_1,d_2,d_1^{â€²},d_2^{â€²},d^{â€²â€²}â‰¥0.$ Then

$$\begin{aligned}
u_1â‹…d_1+u_2â‹…d_2 &= u_1â‹…(d_1^{â€²}+d^{â€²â€²})+u_2â‹…d_2 \\
&= u_1â‹…d_1^{â€²}+u_1â‹…d^{â€²â€²}+u_2â‹…d_2 \\
&â‰¤ u_1â‹…d_1^{â€²}+u_2â‹…d^{â€²â€²}+u_2â‹…d_2 \\
&= u_1â‹…d_1^{â€²}+u_2â‹…(d_2+d^{â€²â€²}) \\
&= u_1â‹…d_1^{â€²}+u_2â‹…d_2^{â€²},
\end{aligned}$$

where $d_1=d_1^{â€²}+d^{â€²â€²}$ and $d_2=d_2^{â€²}-d^{â€²â€²}.$


## All Cross-assignments
We can construct the set of all minimizing difference vectors by using cross-assignment over all possible orderings of vector $ğ®.$ We can generate all possible ordering of $ğ®$ by generating all permutations of $I.$ Let $\mathcal{P}(I)$ define the set of all permutations of set $I.$

$$Î”_ğ©=\{ğ^{âˆ—}(ğ®)âˆ£âˆ€ğ®\}=\{ğ^{âˆ—}(I^{â€²})âˆ£I^{â€²}âˆˆ\mathcal{P}(I)\}.$$

There are a finite amount of permutations $|\mathcal{P}(I)|=k!$ which implies $|Î”_ğ©|â‰¤k!.$
